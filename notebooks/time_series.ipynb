{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation of a time series\n",
    "\n",
    "This example shows how to interpolate a time series using the library.\n",
    "\n",
    "In this example, we consider the time series of MSLA maps distributed by AVISO/CMEMS.\n",
    "\n",
    "## Initialize Dataset\n",
    "\n",
    "Here we load the dataset from the zarr store. Note that this very large dataset initializes nearly instantly, and we can see the full list of variables and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import intake\n",
    "cat = intake.Catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore\"\n",
    "                     \"/master/intake-catalogs/ocean.yaml\")\n",
    "ds = cat[\"sea_surface_height\"].to_dask()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle the time series\n",
    "\n",
    "We implement a class to handle a time series and on demand loading the data required to interpolate data over a specific time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyinterp.backends.xarray\n",
    "\n",
    "\n",
    "class TimeSeries:\n",
    "    \"\"\"Handling of MSLA AVISO maps\"\"\"\n",
    "\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "        self.series, self.dt = self._load_ts()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _is_sorted(array):\n",
    "        indices = np.argsort(array)\n",
    "        return np.all(indices == np.arange(len(indices)))\n",
    "\n",
    "    def _load_ts(self):\n",
    "        \"\"\"Loading the time series into memory.\"\"\"\n",
    "        time = self.ds.time\n",
    "        assert self._is_sorted(time)\n",
    "\n",
    "        series = pd.Series(time)\n",
    "        frequency = set(np.diff(series.values.astype(\"datetime64[s]\")).astype(\"int64\"))\n",
    "        if len(frequency) != 1:\n",
    "            raise RuntimeError(\n",
    "                \"Time series does not have a constant step between two \"\n",
    "                f\"grids: {frequency} seconds\")\n",
    "        return series, datetime.timedelta(seconds=float(frequency.pop()))\n",
    "    \n",
    "    def load_dataset(self, varname, start, end):\n",
    "        \"\"\"Loading the time series into memory for the defined period.\n",
    "\n",
    "        Args:\n",
    "            varname (str): Name of the variable to be loaded into memory.\n",
    "            start (datetime.datetime): Date of the first map to be loaded.\n",
    "            end (datetime.datetime): Date of the last map to be loaded.\n",
    "\n",
    "        Return:\n",
    "            pyinterp.backends.xarray.Grid3D: The interpolator handling the\n",
    "            interpolation of the grid series.\n",
    "        \"\"\"\n",
    "        if start < self.series.min() or end > self.series.max():\n",
    "            raise IndexError(\n",
    "                f\"period [{start}, {end}] out of range [{self.series.min()}, \"\n",
    "                f\"{self.series.max()}]\")\n",
    "        first = start - self.dt\n",
    "        last = end + self.dt\n",
    "\n",
    "        selected = self.series[(self.series >= first) & (self.series < last)]\n",
    "        print(f\"fetch data from {selected.min()} to {selected.max()}\")\n",
    "        \n",
    "        data_array = ds[varname].isel(time=selected.index)\n",
    "        return pyinterp.backends.xarray.Grid3D(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Finally, the functions necessary to load the test datset into memory are added. This file contains several columns defining the float identifier, the date of the measurement, the longitude and the latitude of the measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnes_jd_to_datetime(seconds):\n",
    "    \"\"\"Convert a date expressed in seconds since 1950 into a calendar\n",
    "    date.\"\"\"\n",
    "    return datetime.datetime.utcfromtimestamp(\n",
    "        ((seconds / 86400.0) - 7305.0) * 86400.0)\n",
    "\n",
    "\n",
    "def load_positions():\n",
    "    \"\"\"Loading and formatting the dataset.\"\"\"\n",
    "    df = pd.read_csv(\"../tests/dataset/positions.csv\",\n",
    "                     header=None,\n",
    "                     sep=r\";\",\n",
    "                     usecols=[0, 1, 2, 3],\n",
    "                     names=[\"id\", \"time\", \"lon\", \"lat\"],\n",
    "                     dtype=dict(id=np.uint32,\n",
    "                                time=np.float64,\n",
    "                                lon=np.float64,\n",
    "                                lat=np.float64))\n",
    "    df.mask(df == 1.8446744073709552e+19, np.nan, inplace=True)\n",
    "    df[\"time\"] = df[\"time\"].apply(cnes_jd_to_datetime)\n",
    "    df.set_index('time', inplace=True)\n",
    "    df[\"sla\"] = np.nan\n",
    "    return df.sort_index()\n",
    "\n",
    "df = load_positions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of interpolation\n",
    "\n",
    "We create the object that will handle the download of data for the periods required for the interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = TimeSeries(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below, allows to cluster the processing period into sub-periods in order to load the grids in blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periods(df, time_series, frequency='W'):\n",
    "    \"\"\"Return the list of periods covering the time series loaded in\n",
    "    memory.\"\"\"\n",
    "    period_start = df.groupby(\n",
    "        df.index.to_period(frequency))[\"sla\"].count().index\n",
    "\n",
    "    for start, end in zip(period_start, period_start[1:]):\n",
    "        start = start.to_timestamp()\n",
    "        if start < time_series.series[0]:\n",
    "            start = time_series.series[0]\n",
    "        end = end.to_timestamp()\n",
    "        yield start, end\n",
    "    yield end, df.index[-1] + time_series.dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the interpolation function is written for one of the sub-periods selected by the function `periods`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(df, time_series, start, end):\n",
    "    \"\"\"Interpolate the time series over the defined period.\"\"\"\n",
    "    interpolator = time_series.load_dataset(\"sla\", start, end)\n",
    "    mask = (df.index >= start) & (df.index < end)\n",
    "    selected = df.loc[mask, [\"lon\", \"lat\"]]\n",
    "    df.loc[mask, [\"sla\"]] = interpolator.trivariate(dict(\n",
    "        longitude=selected[\"lon\"].values,\n",
    "        latitude=selected[\"lat\"].values,\n",
    "        time=selected.index.values),\n",
    "        interpolator=\"inverse_distance_weighting\",\n",
    "        num_threads=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start, end in periods(df, time_series, frequency='M'):\n",
    "    interpolate(df, time_series, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the SLA for a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_id = 62423050\n",
    "selected_float = df[df.id == float_id]\n",
    "first = selected_float.index.min()\n",
    "last = selected_float.index.max()\n",
    "size = (selected_float.index - first) / (last-first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(111, projection=ccrs.PlateCarree(central_longitude=180))\n",
    "sc = ax.scatter(\n",
    "    selected_float.lon,\n",
    "    selected_float.lat,\n",
    "    s=size*100,\n",
    "    c=selected_float.sla,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap='jet')\n",
    "ax.coastlines()\n",
    "ax.set_title(\"Time series of SLA \"\n",
    "             \"(larger points are closer to the last date)\")\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.set_extent([80, 100, 13.5, 25], crs=ccrs.PlateCarree())\n",
    "fig.colorbar(sc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
